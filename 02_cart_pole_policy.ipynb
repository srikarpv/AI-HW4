{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Intution \n",
    "\n",
    "The policy pushes the cart to the right otherwise the policy pushes the cart to the left to ensure the pole is maintained in an upright position through out the episode.\n",
    "\n",
    "## Sudo code\n",
    "\n",
    "* We move the cart forward and backward based on the pole movement.\n",
    "* We move the cart forward when the angle of the pole is greater than 0 (ie. pole turning right), else we move it backwards. This will ensure the pole to stay upright(basic physics).\n",
    "* When cart moves to the extreme right side, the policy implemented will pull the cart towards the left to ensure the episode does not terminate quickly and vice versa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "state1,state2 = 0,1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def policy(w,s):\n",
    "    total = 0\n",
    "    for _ in np.arange(100):\n",
    "        movement = state1 if np.matmul(w,s) < 0 else state2\n",
    "        \n",
    "        #Policy(back and forth motion)\n",
    "        if w[0] + w[1] >= 1.7:\n",
    "            movement = state1\n",
    "        elif w[0] + w[1] <= -1.7:\n",
    "            movement = state2\n",
    "        \n",
    "        s, reward, done, _ = env.step(movement)\n",
    "        total += reward\n",
    "        if done:\n",
    "            env.reset()\n",
    "            break\n",
    "    return total, w[0], w[2], done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def action(s):\n",
    "    w = None\n",
    "    done = False\n",
    "    count = 0\n",
    "    next_step = 0\n",
    "    angle = 0\n",
    "    \n",
    "    while count < 100:\n",
    "        \n",
    "        w = np.random.rand(4) * 2.0 - 1.0\n",
    "        reward, pos, angle, done = policy(w, s)\n",
    "        if not done:\n",
    "            count = 0\n",
    "        else:\n",
    "            count += 1\n",
    "        next_step += 1\n",
    "    print (\"Highest reward achieved, with pole angle\", angle)\n",
    "\n",
    "    return count, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation(i):\n",
    "    s = env.reset()\n",
    "    count, w = action(s)\n",
    "    print(\"Total runs:\", count)\n",
    "    print(\"Weight:\", w)\n",
    "    print(\"---------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Highest reward achieved, with pole angle -0.8109949030740726\n",
      "Total runs: 100\n",
      "Weight: [ 0.18691963  0.95679187 -0.8109949  -0.54333497]\n",
      "---------------------------------------\n",
      "Highest reward achieved, with pole angle -0.7032527519112874\n",
      "Total runs: 100\n",
      "Weight: [-0.48629585  0.98922207 -0.70325275 -0.25454779]\n",
      "---------------------------------------\n",
      "Highest reward achieved, with pole angle -0.3038818531849228\n",
      "Total runs: 100\n",
      "Weight: [ 0.84852431 -0.59903332 -0.30388185 -0.1017766 ]\n",
      "---------------------------------------\n",
      "Highest reward achieved, with pole angle -0.25355724227104526\n",
      "Total runs: 100\n",
      "Weight: [ 0.00387969  0.92190257 -0.25355724  0.72895072]\n",
      "---------------------------------------\n",
      "Highest reward achieved, with pole angle 0.3191678297630014\n",
      "Total runs: 100\n",
      "Weight: [-0.43061236  0.04110224  0.31916783  0.03044488]\n",
      "---------------------------------------\n",
      "Highest reward achieved, with pole angle -0.5532271195582328\n",
      "Total runs: 100\n",
      "Weight: [ 0.83484333 -0.92071176 -0.55322712 -0.97863558]\n",
      "---------------------------------------\n",
      "Highest reward achieved, with pole angle 0.8200594887680173\n",
      "Total runs: 100\n",
      "Weight: [0.18631023 0.6827897  0.82005949 0.28962388]\n",
      "---------------------------------------\n",
      "Highest reward achieved, with pole angle -0.540711205949969\n",
      "Total runs: 100\n",
      "Weight: [ 0.82628488  0.55370771 -0.54071121  0.74698421]\n",
      "---------------------------------------\n",
      "Highest reward achieved, with pole angle -0.370226614554487\n",
      "Total runs: 100\n",
      "Weight: [ 0.74866024  0.71805191 -0.37022661 -0.33519179]\n",
      "---------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for i in range(9):\n",
    "    evaluation(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
